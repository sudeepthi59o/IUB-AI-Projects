# a1-release

Authors: Frangil Ramirez Koteich (fraramir), Pranay Chowdary Namburi (pnambur), Sudeepthi Rebbalapalli (surebbal)

## Part 1 
    - The state space are all the possible orderings of the list [1,2,3,4,5], which is denoted by S in the assignment description.
    - The successor function is successors(), which basically just swaps two adjacent fairies and returns the resulting list.
    - The edge weights were defined as 1. For example, a path of 5 moves has cost 5.
    - The goal state is to rearrange the fairies in ascending order of 1 through N, where N = 5. Our goal test if whether a given state S_i == [1, 2, ..., N]. Once that evaluates to True, we return the solution path and terminate.
    - For our heuristic, we counted the inversion pairs in the list of N numbers. Initially we used two other heuristics: the first one counted the number of fairies that were out of place, and the second one added the total distance from the current position of each fairy to the position where it should be placed at (similar to Manhattan distance but in a 1D array). Both of those heuristics work; however, thinking about Problems 2 and 3, we decided to come up with a more complex heuristic. In one of my other courses, Algorithms Design and Analysis, we analyzed a very efficient algorithm to count inversion pairs in a 1D list. I thought that algorithm would be very suitable for our heuristics in this course. I asked Dr. Leake if we could use an implementation of that algorithm from an external source, and he mentioned it was fine as long as we added references as it is a very well-known algorithm and I had it in my other course. I referenced the algorithm (from the textbook of my Algorithms course), and I also referenced the implementation of the algorithm. 
    In short, we ended up counting inversion pairs as our heuristic. In this case, our heuristic is admissible because it is exact. That is, it counts the number of inversion pairs, and we can move two fairies in one move (i.e., a pair of fairies), our heuristics returns the exact cost of the solution path. Therefore, it is admissible.

    - Our search algorithm is A*, and we are actually doing a tree search in this case. Since the state space is so small we are not keeping track of which nodes have been visited or not. In short, we begin by computing all the successors of the initial state, calculate the f() value of each successor, which is the sum of the path cost plus our heuristic's value, and add the tuples of (f, state and path to that state) to a priority queue. Then we pop the tuple with the smallest f value from the priority queue and repeat the process, until our goal test evaluates to true. Once that happens, we return the solution path.

    - For this problem, besides trying the 3 different heuristics mentioned above, we did not face any major issues.

## Part 2
    - For this problem, we also started by doing a tree search, not keeping track of which nodes we had visited. The state space is the set of all possible boards. That is, all the possible arrangements of the numbers in the puzzle. Our successor function performs each of the valid moves described in the assignment to the board, and returns the results. Notice that for every state, the set of possible actions are: R_i, L_i, U_i, D_i for i from 1 through 5, which adds up to 20 moves, and rotating the inner or outer ring clockwise or counterclockwise, for an additional 4 moves. Thus, for each state, there are 24 successor states. Our successor function returns each successor state with the corresponding accion that was taken. The edge weights are also 1 in this case, since every move has constant cost. The goal state is to have the sorted 5x5 puzzle as shown in the assignment description. Again, our goal test is whether a given state S_i == solution. Once that evaluates to True, we return the solution path and terminate. 

    - As for our heuristic functions, we spent a tremenedous amount of time working on them. Intially we tried to use a variation of the heuristic we used in Part 1, which counts the number of inversions in a 1D array. However, in this case, we have a 5x5 matrix. Thus, we counted the number of inversions in each row and/or column (we tried multiple different things). Nonetheless, the difference is that in this case we can create/eliminate up to 4 inversions in a given row with a single move. Hence, we were dividing the total number of inversions in the matrix by 4. This worked very well, as our code was finding an optimal solution path for board1.txt in just 28 seconds. As a metric, we were also keeping track of the number of nodes expanded. With this heuristic, finding a solution path for board1.txt took 28 seconds by expanding around 8k nodes. Continuation in next bullet.

    - Hence, we have that the heuristic mentioned above was working very well. However, after testing throughly with some custom boards, it broke for some very specific ones. Trying to fix it, I tried about a dozen different heuristics. The first two were simple ones: counting the number of tiles out of place and adding up the Manhattan distance. Obviously, in order to make them admissible, we were compensating the value returned by these heuristics using some constants since we could, for example, reduce the total Manhattan distance of a puzzle by up to 16 units in just one single outer ring rotation. These heuristcs worked, but they were expanding upwards of 50k nodes. Hence, we decided not to use them.
    We kept trying to make the counting-inversions heuristic work. When debugging, I noticed a very, very strange phenomena with that heuristic. Recall that I was dividing the total number of inversions by 4. If I divided by 2 instead of by 4, the code could find the solution for board1.txt in 26 seconds expanding 7k nodes. I thought that it was odd that a constant factor would reduce the number of visited nodes by 1k. I met with Dr. Leake about it and he also found it odd. Anyway, dividing by 2 still did not fix the issue with some of the custom boards. Part of the problem is due to the ring rotations, which can create a tremendous amount of total inversions in just one move. Thus, I thought about focusing on the number of inversions only along the inner and outer rings, and not the rows and columns. The reason for that is that if the rings are sorted (or have very few inversions), then we are very close to a solution. If we only look at rows and columns, maybe we were diverging away from a solution because it involved rotating a ring which created multiple inversions. Hence, this new heuristic that focused only on the rings also managed to find a solution for board1, but it expanded considerably more nodes. Also, it still did not return a solution for some custom boards. Continuation in next bullet.

    - Moreover, I decided to tried some combination of the two heuristics (row/column and rings). Picking the max of those, still did not improve results. Dividing by larger constants to be extra sure they are admissible resulted in considerably more nodes being expanded for board1. The fastest solution was still dividing the inversions in the row/columns by 2. I also tried normalizing the number of inversions returned by the heuristic to a number between 0 and 1, so that the heuristic would be consistent. That is because the cost from one state to another is only 1, but the difference in the number of inversions could be larger. Thus, by normalizing the heuristic value we can guarantee that it is both consistent and admissible. Nonetheless, with this heuristic the program took considerably longer to find a solution for board1 (upwards of 100k nodes), and it would still skip the solution for some custom boards. Thus, I tried randomizing the heuristic. The reasoning was that maybe by adding some randomization into the heuristic it would not skip the solution for the custom boards. I tried both multiplying the number of inversions by a random value between 0 and 1, and dividing the number of inversions by (4 * random value between 0 and 1). Both of those still managed to find a solution for board1 in under a minute, but not for the custom board. Continuation in next bullet (almost done).

    - Something that I found very, very odd, is how the value of the constant by which I was dividing the number of inversions affected the performance of our code. Out of frustration, I tried multiple different values, some of them even with decimal values. There was no particular reason why I tried some of those decimal values. Nonetheless, surprisingly enough, dividing the number of inversions by 3.15 makes the program find a solution in 2 seconds expanding only about 900 nodes. I have spent the past 3 days trying to figure out why and I still cannot fully explain it. Even more strangely, dividing by 3.00 finds the solution expanding 2-3k nodes, but dividing by 3.000001 also expands only 900 nodes. Such a small difference in the value of the constant causes such a big difference in performance. Nonetheless, to finish this summary, I converted this into a graph search by keeping track of which nodes have been visited. By doing so, and by dividing by 3.15, the program can find a solution for board1 in 1 second expanding only around 400 nodes. I will turn that version in as it is by far the most efficient one; however, logically the solution should be divided by 4 as we can solve at most 4 inversions in a given row in 1 move, so it is admissible. Changing the constant value from 3.15 to 4 (and keeping track of visited nodes) still finds the exact same solution in a very short period of time, which is why I decided to turn in the most efficient version. The only problem with keeping track of visited nodes is that the program becomes significantly slower. Lastly, it is worth mentioning that I also ttried working backwards from the solution towards the initial state, but that did not yield better results.

    - As for our description of how algorithm works, the content above probably suffices. However, we are doing something very similar as in Part 1. Using A*, we do a graph search by keeping track of visited nodes, and we add to a priority queue a tuple containing the f value and the state and path used to reach that state. That is, a tuple of the form (f, state and path to that state). The f value is computed by adding up the heuristic value plus the cost of the path (which is just the length of the path as each move has cost 1). We then pop from the priority queue the tuple with the smallest f value. Also, in this case, our code was not popping the correct states from the queue because it was considering both the f value AND the state itself whenever it was choosing which element to pop from the queue. In order to have the priority queue only consider the f value whenever we popped something from the queue, we had to wrap each tuple of the form (f, state and path) in a class that told the program to ignore the state itself, and only pop from the queue based on the f value of such a state. Such a class is called PrioritizedItem, which basically means that elements from the queue are giving priority based on their f value, and not based on the state itself (although those are related).

    - In this problem, as mentioned at the beginning, the branching factor is 24 because each state has 24 successors. If the solution could be reached in 7 moves, BFS would need to expand O(24^7) nodes in order to reach such a solution.

## Part3

    - The first thing we did in this problem was to build a graph with the cities as nodes and road segments as edges from the city-gps.txt and road-segments.txt. We assigned the distance, speed limit and highway names given in road-segments.txt to the edges of the graph. We also assigned the latitude and longitude in city-gps.txt to the city nodes in the graph. 

    - Next, we realized that there are cities/nodes in the graph without any latitude and longitude. To solve this problem, we set these missing values for the cities to the latitude and longitude of the nearest city in miles if the nearest city had those values. Otherwise we set it to 0,0.

**State** **Space:** The set of nodes in the graph denoting by the cities in city-gps.txt and road-segments.txt.   
**Initial** **State:** The node denoting the start city in the graph.   
**Goal** **State:** The node denoting the end city in the graph.   
**Successor** **Function:** Returns the set of nodes/cities connected to the current node/city through an edge/road segment.   

### Search Formulation for finding the Fewest Number of Segments
**Edge** **Weights:** Weight of each edge is 1 as we are counting the number of segments to the goal.   
**Heuristics:** The heuristic function we used here is a cost of 1 from the current city to the goal state. This is an admissible heuristic because it's the minimum possible segments to reach the goal. 

### Search Formulation for finding the Total Shortest distance
**Edge** **Weights:** Weight of each edge is the distance in miles between the two cities.     
**Heuristics:** The heuristic function we used here is the haversine distance. This is used to calculate the distance between any two point on the earth given the latitude and longitude while accounting for its spherical shape.  

> This is admissible heuristic because it's minimum possible distance between any two cities given the latitude and longitude. (We got the idea for this from the reference: https://www.geeksforgeeks.org/program-distance-two-points-earth/)

### Search Formulation for finding the Fastest Route (given speed limits)
**Edge Weights:** Weight of each edge is the speed limit of the highway connecting the two cities.   
**Heuristics:** The heuristic function we used here is the formula for time calculated by time=(haversine distance/maximum speed limit from the whole graph).  
> This is an admissible heuristic because we are minimizing the distance and maximizing the possible speed so we get the minimum possible time in hours i.e the fastest route between any two cities. 

### Search Formulation for finding the Fastest Delivery time
**Edge** **Weights:** Weight of each edge is the delivery time it takes from the current city to the next city.   
**Heuristics:** The heuristic function we used here is the formula for time calculated by time=(haversine distance/maximum speed limit from the whole graph). We use this heuristic with the assumption that the package does not fall so we can travel at the
maximum speed.   
> This is an admissible heuristic because we are taking the fastest route with the assumption that the package does not fall which is the best case scenario

### Implementation Logic:
    - First I create a fringe that acts as a priority queue. The basic idea here is to traverse through each child and add them to priority queue along with their heuristic cost. Then we pop the first element and do the same till we reach the destination.
    - So, the fringe contains a tuple of (heuristic cost, another tuple(city, and all the traversed cities along the path)). Here, the heuristic cost = f(n) = g(n) + h(n): the g(n) & h(n) varies for different types of costs which are segments, distance, time & delivery time.
> - Distance -> to find the shortest distance from the source to destination.   
> - Time -> to find the shortest time it takes from source to destination.   
> - Segments -> to find the minimum amount of road segments travelled from source to distance.  
> - Delivery -> to find the shortest time it takes for the delivery driver togo from source to detination. 
> 
> So, for each type of cost, we have to create different g(n) & h(n).

    - Created the heuristic functions as mentioned above. For the heuristic function of distance, first we used euclidean distance. The code was running successfully. So used the same distance for creating the heuristic function of time, to calculate the minimum time. But for that I found there were some inconsistencies. Because when we find the euclidean distance for the given latitudes and longitudes, it is giving the value in some planar units. So to the shortest distance from latitudes & longitudes we used Haversine formula. 
> https://www.geeksforgeeks.org/program-distance-two-points-earth/#
    - After changing the formula, it is working fine. Hence continued with this approach. 

    -And we used the similar heuristic function for delivery hours that is used for time as well. Because the minimum possible time to deliver is the same as shortest possible time from current state assuming the package doesn't fall.

